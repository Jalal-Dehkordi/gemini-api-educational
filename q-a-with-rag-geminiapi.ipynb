{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T04:58:29.240856Z","iopub.execute_input":"2025-04-09T04:58:29.241188Z","iopub.status.idle":"2025-04-09T04:58:29.246369Z","shell.execute_reply.started":"2025-04-09T04:58:29.241163Z","shell.execute_reply":"2025-04-09T04:58:29.245328Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Project Objective\n\nThis project is an integrated document processing system that utilizes the capabilities of the Gemini API to perform three main tasks:\n\n2. **Question and Answering (Q&A)** based on external documents using **RAG** architecture and the Chroma vector database.\n","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom IPython.display import Markdown\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T04:57:33.246521Z","iopub.execute_input":"2025-04-09T04:57:33.247105Z","iopub.status.idle":"2025-04-09T04:57:33.252609Z","shell.execute_reply.started":"2025-04-09T04:57:33.247070Z","shell.execute_reply":"2025-04-09T04:57:33.251529Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'0.2.2'"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Setting Up Your API Key\n\nTo use the services provided by external APIs, you need to set up your API key. Follow these steps:\n\n1. **Obtain an API Key**: If you don't have an API key, you can get one from [AI Studio](https://aistudio.google.com/). Detailed instructions are available in the official documentation.\n\n2. **Store the API Key in Kaggle Secrets**:\n   - Go to the **Add-ons** menu in Kaggle.\n   - Select **Secrets** and add your API key with the name `GOOGLE_API_KEY`.\n\n3. **Use the API Key in Your Code**:\n   - Once the key is stored, you can access it in your notebook using `os.environ[\"GOOGLE_API_KEY\"]`.\n\n> **Note**: Always keep your API key secure and avoid sharing it publicly.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:01:03.977645Z","iopub.execute_input":"2025-04-09T05:01:03.978109Z","iopub.status.idle":"2025-04-09T05:01:04.120003Z","shell.execute_reply.started":"2025-04-09T05:01:03.978074Z","shell.execute_reply":"2025-04-09T05:01:04.118950Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Large Language Models (LLMs) face two major limitations:\n\n1. **Limited Knowledge**: They only \"know\" the information they were trained on.\n2. **Limited Context Window**: They have a restricted input context size.\n\nTo address these limitations, the **Retrieval Augmented Generation (RAG)** technique is used. RAG consists of three key stages:\n\n1. **Indexing**: Create a vector database to enable quick lookup of relevant information.\n2. **Retrieval**: Retrieve documents related to the user's query.\n3. **Generation**: Generate a natural language response using the retrieved information.\n\n---\n### Tools Used in This part:\n\n- **Gemini API**: To create a vector database.\n- **Chroma**: An open-source vector database for storing embeddings, embedding documents, and searching for relevant information.\n\n> With Chroma, you can efficiently store, search, and retrieve documents to provide intelligent answers to user queries.","metadata":{}},{"cell_type":"markdown","source":"### Data\n\nHere is a small set of documents you will use to create an embedding database.","metadata":{}},{"cell_type":"code","source":"DOCUMENT1 = \"Operating the Climate Control System  Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"\nDOCUMENT2 = 'Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.'\nDOCUMENT3 = \"Shifting Gears Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"\n\ndocuments = [DOCUMENT1, DOCUMENT2, DOCUMENT3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:02:49.242682Z","iopub.execute_input":"2025-04-09T05:02:49.243191Z","iopub.status.idle":"2025-04-09T05:02:49.248706Z","shell.execute_reply.started":"2025-04-09T05:02:49.243153Z","shell.execute_reply":"2025-04-09T05:02:49.247199Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Creating the Embedding Database with ChromaDB\n\nIn this step, you will create a vector database using **ChromaDB** to store and retrieve document embeddings. To generate embeddings, we will implement a custom function that utilizes the **Gemini API**.\n\n## Key Concepts:\n- **Documents**: These are the items stored in the database. They are inserted first and later retrieved based on their semantic similarity.\n- **Queries**: These are the search terms or textual descriptions used to find relevant documents in the database.\n\n## Implementation Details:\n1. Use the `task_type` parameter as **retrieval_document** when generating embeddings for documents. This ensures that the embeddings are optimized for storage and retrieval.\n2. Later, when querying the database, use **retrieval_query** for generating query embeddings.","metadata":{}},{"cell_type":"code","source":"#!pip install chromadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:06:13.234602Z","iopub.execute_input":"2025-04-09T05:06:13.235036Z","iopub.status.idle":"2025-04-09T05:06:13.240522Z","shell.execute_reply.started":"2025-04-09T05:06:13.235004Z","shell.execute_reply":"2025-04-09T05:06:13.239013Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class GeminiEmbeddingFunction(EmbeddingFunction):\n    def __init__(self):\n        self.document_mode = True  \n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:12:32.608991Z","iopub.execute_input":"2025-04-09T05:12:32.609362Z","iopub.status.idle":"2025-04-09T05:12:32.615657Z","shell.execute_reply.started":"2025-04-09T05:12:32.609331Z","shell.execute_reply":"2025-04-09T05:12:32.614369Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"Now create a Chroma database client that uses the **GeminiEmbeddingFunction** and populate the database with the documents you defined above.","metadata":{}},{"cell_type":"code","source":"import chromadb\n\nDB_NAME = \"googlecardb\"\n\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.document_mode = True\n\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n\ndb.add(documents=documents, ids=[str(i) for i in range(len(documents))])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:12:36.989338Z","iopub.execute_input":"2025-04-09T05:12:36.989658Z","iopub.status.idle":"2025-04-09T05:12:37.396689Z","shell.execute_reply.started":"2025-04-09T05:12:36.989633Z","shell.execute_reply":"2025-04-09T05:12:37.395534Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"### Confirm that the data was inserted by looking at the database.","metadata":{}},{"cell_type":"code","source":"db.count()\n# db.peek(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:12:59.833039Z","iopub.execute_input":"2025-04-09T05:12:59.833537Z","iopub.status.idle":"2025-04-09T05:12:59.845165Z","shell.execute_reply.started":"2025-04-09T05:12:59.833488Z","shell.execute_reply":"2025-04-09T05:12:59.844025Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## **Retrieval**: Find relevant documents\nTo search the **Chroma database**, call the query method. Note that you also switch to the retrieval_query mode of embedding generation.","metadata":{}},{"cell_type":"code","source":"# Switch to query mode when generating embeddings.\nembed_fn.document_mode = False\n\n# Search the Chroma DB using the specified query.\nquery = \"How do you use the touchscreen to play music?\"\n\nresult = db.query(query_texts=[query], n_results=1)\n[all_passages] = result[\"documents\"]\n\nMarkdown(all_passages[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:13:16.114541Z","iopub.execute_input":"2025-04-09T05:13:16.114940Z","iopub.status.idle":"2025-04-09T05:13:16.518428Z","shell.execute_reply.started":"2025-04-09T05:13:16.114900Z","shell.execute_reply":"2025-04-09T05:13:16.517442Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs."},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Augmented Generation: Answer the Question\n\nAfter retrieving relevant passages from a set of documents (the retrieval step), you can now construct a generation prompt to allow the Gemini API to generate a final answer.","metadata":{}},{"cell_type":"code","source":"query_oneline = query.replace(\"\\n\", \" \")\n\n# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\nprompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \nBe sure to respond in a complete sentence, being comprehensive, including all relevant background information. \nHowever, you are talking to a non-technical audience, so be sure to break down complicated concepts and \nstrike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n\nQUESTION: {query_oneline}\n\"\"\"\n\n# Add the retrieved documents to the prompt.\nfor passage in all_passages:\n    passage_oneline = passage.replace(\"\\n\", \" \")\n    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n\nprint(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:13:35.981612Z","iopub.execute_input":"2025-04-09T05:13:35.981977Z","iopub.status.idle":"2025-04-09T05:13:35.989127Z","shell.execute_reply.started":"2025-04-09T05:13:35.981949Z","shell.execute_reply":"2025-04-09T05:13:35.987866Z"}},"outputs":[{"name":"stdout","text":"You are a helpful and informative bot that answers questions using text from the reference passage included below. \nBe sure to respond in a complete sentence, being comprehensive, including all relevant background information. \nHowever, you are talking to a non-technical audience, so be sure to break down complicated concepts and \nstrike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n\nQUESTION: How do you use the touchscreen to play music?\nPASSAGE: Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"**Now use the generate_content method to to generate an answer to the question.**","metadata":{}},{"cell_type":"code","source":"answer = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt)\n\nMarkdown(answer.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:13:54.667240Z","iopub.execute_input":"2025-04-09T05:13:54.667599Z","iopub.status.idle":"2025-04-09T05:13:55.316934Z","shell.execute_reply.started":"2025-04-09T05:13:54.667560Z","shell.execute_reply":"2025-04-09T05:13:55.315829Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"To play music on your Googlecar, simply touch the \"Music\" icon on the large touchscreen display.\n"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"###  Congrats on building a Retrieval-Augmented Generation app!","metadata":{}}]}